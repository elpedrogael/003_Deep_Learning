{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96af2ddc-dccc-471b-83bc-d5a80ce21fcb",
   "metadata": {},
   "source": [
    "<img style=\"float: right; margin: 5px 5px 20px 20px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/d/db/Logo_ITESO_normal.jpg\" width=\"100px\" height=\"75px\"/>\n",
    "\n",
    "# 003 Deep learning\n",
    "\n",
    "### Microstructures and trading systems\n",
    "\n",
    "> **Evelin Ramirez, Pedro Gael Rayas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1246c9-662e-4d37-85a9-5183fe301b59",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38ca05c-ab98-4f5f-a1a9-5b8e48107c50",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a71b58a9-903b-4372-a4a6-e9c0ca96464e",
   "metadata": {},
   "source": [
    "## Introducción "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eff1a0-6cc8-451b-b8f2-2779873237ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a93a0768-71ba-4279-a99d-907335e6b59d",
   "metadata": {},
   "source": [
    "## Metodología y código"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0a436c-fb37-4657-bb33-b58fa0e88b9e",
   "metadata": {},
   "source": [
    "### 0. Importar librerías "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96f1ad3e-5830-4d8b-af94-5d1dcf2c1978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import ta\n",
    "import logging\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4675e739-094b-485c-aa5e-b69caafb8f6a",
   "metadata": {},
   "source": [
    "### 1. Carga de datos \n",
    "\n",
    "* Se utiliza el archivo CSV 'aapl_5m_train.csv' proporcionado por el profesor, que contiene datos históricos de las acciones de Apple registrados cada 5 minutos. Los datos abarcan el período comprendido desde el 04 de enero de 2021 a las 14:30:00 hasta el 30 de diciembre de 2022 a las 21:00:00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8180a23-cd36-4ea7-9960-903d619c1036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño inicial de data: 39160\n"
     ]
    }
   ],
   "source": [
    "# Carga de datos\n",
    "data = pd.read_csv('aapl_5m_train.csv').dropna()\n",
    "print(f\"Tamaño inicial de data: {len(data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178f0254-5a00-440e-b2e3-aea1767a1b8c",
   "metadata": {},
   "source": [
    "### 2. Preparación y Entrenamiento del Modelo LSTM\n",
    "\n",
    "Se normalizan las variables y se generan secuencias temporales mediante una ventana de lookback para capturar la dinámica de los precios y los indicadores. Posteriormente, se construye y entrena un modelo LSTM con dos capas (50 unidades cada una), intercalando capas de dropout para reducir el sobreajuste, y se utiliza la salida para clasificar la dirección del cambio en el precio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5b39564-87c6-40e9-912e-b26c765110bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para preparar datos para LSTM\n",
    "def prepare_lstm_data(dataset, lookback=20):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(dataset[[\"Close\", \"RSI\", \"BB\", \"MACD\", \"MACD_signal\"]])\n",
    "    X, y = [], []\n",
    "    for i in range(lookback, len(scaled_data)):\n",
    "        X.append(scaled_data[i-lookback:i])\n",
    "        y.append(dataset[[\"BUY_SIGNAL\", \"SELL_SIGNAL\"]])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    return X_train, y_train, X_test, y_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cad350be-26ae-4100-9356-66fa5731fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear y entrenar el modelo LSTM\n",
    "def train_lstm(X_train, y_train, lookback=20):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(lookback, 5)))\n",
    "    model.add(LSTM(50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(50))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=3, batch_size=32, verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57a80cb-8629-4204-bba4-d2d4295d4122",
   "metadata": {},
   "source": [
    "### 3. Cálculo de Métricas de Desempeño\n",
    "\n",
    "Esta función evalúa la eficiencia de la estrategia de trading a través de los siguientes pasos:\n",
    "\n",
    "* Se convierte la evolución del portafolio en retornos porcentuales.\n",
    "* Se calcula el Sharpe Ratio dividiendo la media de los retornos (ajustada por una tasa libre de riesgo) entre su desviación estándar y anualizando el resultado.\n",
    "* El Sortino Ratio se obtiene de forma similar, pero usando solo los retornos negativos para medir el riesgo a la baja.\n",
    "* El Calmar Ratio se determina dividiendo el retorno anualizado entre el máximo drawdown, representando la peor caída acumulada del portafolio.\n",
    "* Se calcula el porcentaje de operaciones ganadoras sobre el total de operaciones para obtener el Win/Loss Percentage.\n",
    "* Esta metodología permite evaluar tanto la rentabilidad como la gestión del riesgo de la estrategia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b923ad6",
   "metadata": {},
   "source": [
    "### 4. Preprocessing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ccc3ac48-be13-42e8-a77a-8a7580827be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare_lstm_data is defined\n",
    "def prepare_lstm_data(dataset, lookback=20, features=None):\n",
    "    if features is None:\n",
    "        features = [\"Close\", \"RSI\", \"BB\", \"MACD\", \"MACD_signal\"]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(dataset[features])\n",
    "    X, y = [], []\n",
    "    for i in range(lookback, len(scaled_data)):\n",
    "        X.append(scaled_data[i - lookback:i])\n",
    "        y.append(1 if scaled_data[i, 0] > scaled_data[i - 1, 0] else 0)  # Binary classification based on Close\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    train_size = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, scaler\n",
    "\n",
    "# Updated train_lstm with Input layer\n",
    "def train_lstm(X_train, y_train, lookback, units=50):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=3, batch_size=32, verbose=0)\n",
    "    return model\n",
    "\n",
    "# Updated calculate_metrics to handle NaN\n",
    "def calculate_metrics(portfolio_value, wins, losses):\n",
    "    returns = pd.Series(portfolio_value).pct_change().dropna()\n",
    "    mean_ret = returns.mean()\n",
    "    std_ret = returns.std()\n",
    "    if std_ret == 0 or np.isnan(mean_ret) or np.isnan(std_ret):\n",
    "        return {\"Sharpe\": -float('inf')}  # Penalize invalid cases\n",
    "    sharpe = (mean_ret / std_ret) * np.sqrt(252)  # Annualized Sharpe Ratio\n",
    "    return {\"Sharpe\": sharpe}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0621c012-abda-44c1-a961-6a3cd77b2b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization for RSI\n",
    "\n",
    "# Objective function for RSI\n",
    "def objective_rsi(trial, data, verbose=False):\n",
    "    rsi_window = trial.suggest_int(\"rsi_window\", 10, 100)\n",
    "    rsi_lower = trial.suggest_int(\"rsi_lower\", 5, 35)\n",
    "    rsi_upper = trial.suggest_int(\"rsi_upper\", 65, 95)\n",
    "    stop_loss = trial.suggest_float(\"stop_loss\", 0.01, 0.2)\n",
    "    take_profit = trial.suggest_float(\"take_profit\", 0.01, 0.2)\n",
    "    n_shares = trial.suggest_categorical(\"n_shares\", [1000, 2000, 3000, 3500, 4000])\n",
    "    lookback = trial.suggest_int(\"lookback\", 10, 50)\n",
    "\n",
    "    dataset = data.copy()\n",
    "    rsi = ta.momentum.RSIIndicator(dataset.Close, window=rsi_window)\n",
    "    dataset[\"RSI\"] = rsi.rsi()\n",
    "\n",
    "    X_train, y_train, X_test, y_test, scaler = prepare_lstm_data(dataset.dropna(), lookback=lookback, features=[\"Close\", \"RSI\"])\n",
    "    model = train_lstm(X_train, y_train, lookback=lookback)\n",
    "\n",
    "    scaled_data = scaler.transform(dataset[[\"Close\", \"RSI\"]])\n",
    "    X_full = [scaled_data[i - lookback:i] for i in range(lookback, len(scaled_data))]\n",
    "    X_full = np.array(X_full)\n",
    "    lstm_preds = (model.predict(X_full, verbose=0) > 0.5).astype(int).flatten()\n",
    "\n",
    "    dataset = dataset.iloc[lookback:].reset_index(drop=True)\n",
    "    dataset[\"LSTM_BUY\"] = pd.Series(lstm_preds) == 1\n",
    "    dataset[\"LSTM_SELL\"] = pd.Series(lstm_preds) == 0\n",
    "\n",
    "    dataset[\"RSI_BUY\"] = dataset[\"RSI\"] < rsi_lower\n",
    "    dataset[\"RSI_SELL\"] = dataset[\"RSI\"] > rsi_upper\n",
    "\n",
    "    dataset[\"BUY_SIGNAL\"] = dataset[\"RSI_BUY\"]\n",
    "    dataset[\"SELL_SIGNAL\"] = dataset[\"RSI_SELL\"]\n",
    "\n",
    "    dataset = dataset.dropna()\n",
    "    capital = 1000000\n",
    "    com = 0.5 / 100\n",
    "    portfolio_value = [capital]\n",
    "    active_long_pos = None\n",
    "    active_short_pos = None\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "\n",
    "    for i, row in dataset.iterrows():\n",
    "        if active_long_pos:\n",
    "            if row.Close < active_long_pos[\"stop_loss\"]:\n",
    "                pnl = row.Close * n_shares * (1 - com) - active_long_pos[\"cost\"]\n",
    "                capital += active_long_pos[\"cost\"] + pnl\n",
    "                if pnl > 0:\n",
    "                    wins += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "                active_long_pos = None\n",
    "            elif row.Close > active_long_pos[\"take_profit\"]:\n",
    "                pnl = row.Close * n_shares * (1 - com) - active_long_pos[\"cost\"]\n",
    "                capital += active_long_pos[\"cost\"] + pnl\n",
    "                if pnl > 0:\n",
    "                    wins += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "                active_long_pos = None\n",
    "\n",
    "        if active_short_pos:\n",
    "            if row.Close > active_short_pos[\"stop_loss\"]:\n",
    "                pnl = active_short_pos[\"revenue\"] - row.Close * n_shares * (1 + com)\n",
    "                capital += pnl\n",
    "                if pnl > 0:\n",
    "                    wins += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "                active_short_pos = None\n",
    "            elif row.Close < active_short_pos[\"take_profit\"]:\n",
    "                pnl = active_short_pos[\"revenue\"] - row.Close * n_shares * (1 + com)\n",
    "                capital += pnl\n",
    "                if pnl > 0:\n",
    "                    wins += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "                active_short_pos = None\n",
    "\n",
    "        if row[\"BUY_SIGNAL\"] and active_long_pos is None and active_short_pos is None:\n",
    "            cost = row.Close * n_shares * (1 + com)\n",
    "            if capital > cost:\n",
    "                capital -= cost\n",
    "                active_long_pos = {\n",
    "                    \"datetime\": row.Datetime,\n",
    "                    \"cost\": cost,\n",
    "                    \"take_profit\": row.Close * (1 + take_profit),\n",
    "                    \"stop_loss\": row.Close * (1 - stop_loss)\n",
    "                }\n",
    "\n",
    "        if row[\"SELL_SIGNAL\"] and active_short_pos is None and active_long_pos is None:\n",
    "            revenue = row.Close * n_shares * (1 - com)\n",
    "            capital += revenue\n",
    "            active_short_pos = {\n",
    "                \"datetime\": row.Datetime,\n",
    "                \"revenue\": revenue,\n",
    "                \"take_profit\": row.Close * (1 - take_profit),\n",
    "                \"stop_loss\": row.Close * (1 + stop_loss)\n",
    "            }\n",
    "\n",
    "        long_value = row.Close * n_shares if active_long_pos else 0\n",
    "        short_value = (active_short_pos[\"revenue\"] - row.Close * n_shares) if active_short_pos else 0\n",
    "        portfolio_value.append(capital + long_value + short_value)\n",
    "\n",
    "    if len(portfolio_value) <= 1:\n",
    "        return -float('inf')\n",
    "    metrics = calculate_metrics(portfolio_value, wins, losses)\n",
    "    return metrics[\"Sharpe\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1118141a-4f44-4d5c-b145-dec0fdd2e118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 19:28:44,457] A new study created in memory with name: no-name-163c3fec-4f61-4981-aa8a-78df37e212ac\n",
      "[I 2025-03-27 19:28:50,866] Trial 0 finished with value: 0.1672539133304027 and parameters: {'rsi_window': 76, 'rsi_lower': 21, 'rsi_upper': 67, 'stop_loss': 0.13915718780040712, 'take_profit': 0.1639530694448835, 'n_shares': 1000, 'lookback': 10}. Best is trial 0 with value: 0.1672539133304027.\n",
      "[I 2025-03-27 19:29:07,735] Trial 1 finished with value: -inf and parameters: {'rsi_window': 87, 'rsi_lower': 23, 'rsi_upper': 82, 'stop_loss': 0.07332686369830341, 'take_profit': 0.1497731486192994, 'n_shares': 2000, 'lookback': 39}. Best is trial 0 with value: 0.1672539133304027.\n"
     ]
    }
   ],
   "source": [
    "# Running the optimization\n",
    "study_rsi = optuna.create_study(direction=\"maximize\")\n",
    "study_rsi.optimize(lambda trial: objective_rsi(trial, data), n_trials=50)\n",
    "print(\"Mejores parámetros RSI:\", study_rsi.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c691112-7796-4986-87e2-625840fc9f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare_lstm_data is defined\n",
    "#Optimization for Bollinger Bands\n",
    "def prepare_lstm_data(dataset, lookback=20, features=None):\n",
    "    if features is None:\n",
    "        features = [\"Close\", \"RSI\", \"BB\", \"MACD\", \"MACD_signal\"]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(dataset[features])\n",
    "    X, y = [], []\n",
    "    for i in range(lookback, len(scaled_data)):\n",
    "        X.append(scaled_data[i - lookback:i])\n",
    "        y.append(1 if scaled_data[i, 0] > scaled_data[i - 1, 0] else 0)  # Binary classification based on Close\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    train_size = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, scaler\n",
    "\n",
    "# Updated train_lstm with Input layer\n",
    "def train_lstm(X_train, y_train, lookback, units=50):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=3, batch_size=32, verbose=0)\n",
    "    return model\n",
    "\n",
    "# Updated calculate_metrics to handle NaN\n",
    "def calculate_metrics(portfolio_value, wins, losses):\n",
    "    returns = pd.Series(portfolio_value).pct_change().dropna()\n",
    "    mean_ret = returns.mean()\n",
    "    std_ret = returns.std()\n",
    "    if std_ret == 0 or np.isnan(mean_ret) or np.isnan(std_ret):\n",
    "        return {\"Sharpe\": -float('inf')}  # Penalize invalid cases\n",
    "    sharpe = (mean_ret / std_ret) * np.sqrt(252)  # Annualized Sharpe Ratio\n",
    "    return {\"Sharpe\": sharpe}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2f78448-5227-49ca-853f-f03a53958803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function for Bollinger Bands\n",
    "def objective_bb(trial, data, verbose=False):\n",
    "    # Hiperparámetros específicos de BB\n",
    "    bb_window = trial.suggest_int(\"bb_window\", 10, 30)\n",
    "    bb_window_dev = trial.suggest_float(\"bb_window_dev\", 1.5, 3.0)\n",
    "    \n",
    "    # Hiperparámetros generales de trading\n",
    "    stop_loss = trial.suggest_float(\"stop_loss\", 0.01, 0.2)\n",
    "    take_profit = trial.suggest_float(\"take_profit\", 0.01, 0.2)\n",
    "    n_shares = trial.suggest_categorical(\"n_shares\", [1000, 2000, 3000, 3500, 4000])\n",
    "    lookback = trial.suggest_int(\"lookback\", 10, 50)\n",
    "\n",
    "    dataset = data.copy()\n",
    "    bb = ta.volatility.BollingerBands(dataset.Close, window=bb_window, window_dev=bb_window_dev)\n",
    "    dataset[\"BB\"] = bb.bollinger_mavg()\n",
    "    dataset[\"BB_lower\"] = bb.bollinger_lband()\n",
    "    dataset[\"BB_upper\"] = bb.bollinger_hband()\n",
    "\n",
    "    X_train, y_train, X_test, y_test, scaler = prepare_lstm_data(dataset.dropna(), lookback=lookback, features=[\"Close\", \"BB\"])\n",
    "    model = train_lstm(X_train, y_train, lookback=lookback)\n",
    "\n",
    "    scaled_data = scaler.transform(dataset[[\"Close\", \"BB\"]])\n",
    "    X_full = [scaled_data[i - lookback:i] for i in range(lookback, len(scaled_data))]\n",
    "    X_full = np.array(X_full)\n",
    "    lstm_preds = (model.predict(X_full, verbose=0) > 0.5).astype(int).flatten()\n",
    "\n",
    "    dataset = dataset.iloc[lookback:].reset_index(drop=True)\n",
    "    dataset[\"LSTM_BUY\"] = pd.Series(lstm_preds) == 1\n",
    "    dataset[\"LSTM_SELL\"] = pd.Series(lstm_preds) == 0\n",
    "\n",
    "    dataset[\"BB_BUY\"] = dataset.Close < dataset[\"BB_lower\"]\n",
    "    dataset[\"BB_SELL\"] = dataset.Close > dataset[\"BB_upper\"]\n",
    "\n",
    "    dataset[\"BUY_SIGNAL\"] = dataset[\"BB_BUY\"]\n",
    "    dataset[\"SELL_SIGNAL\"] = dataset[\"BB_SELL\"]\n",
    "\n",
    "    dataset = dataset.dropna()\n",
    "    capital = 1000000\n",
    "    com = 0.5 / 100\n",
    "    portfolio_value = [capital]\n",
    "    active_long_pos = None\n",
    "    active_short_pos = None\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "\n",
    "    for i, row in dataset.iterrows():\n",
    "        if active_long_pos:\n",
    "            if row.Close < active_long_pos[\"stop_loss\"]:\n",
    "                pnl = row.Close * n_shares * (1 - com) - active_long_pos[\"cost\"]\n",
    "                capital += active_long_pos[\"cost\"] + pnl\n",
    "                if pnl > 0:\n",
    "                    wins += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "                active_long_pos = None\n",
    "            elif row.Close > active_long_pos[\"take_profit\"]:\n",
    "                pnl = row.Close * n_shares * (1 - com) - active_long_pos[\"cost\"]\n",
    "                capital += active_long_pos[\"cost\"] + pnl\n",
    "                if pnl > 0:\n",
    "                    wins += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "                active_long_pos = None\n",
    "\n",
    "        if active_short_pos:\n",
    "            if row.Close > active_short_pos[\"stop_loss\"]:\n",
    "                pnl = active_short_pos[\"revenue\"] - row.Close * n_shares * (1 + com)\n",
    "                capital += pnl\n",
    "                if pnl > 0:\n",
    "                    wins += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "                active_short_pos = None\n",
    "            elif row.Close < active_short_pos[\"take_profit\"]:\n",
    "                pnl = active_short_pos[\"revenue\"] - row.Close * n_shares * (1 + com)\n",
    "                capital += pnl\n",
    "                if pnl > 0:\n",
    "                    wins += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "                active_short_pos = None\n",
    "\n",
    "        if row[\"BUY_SIGNAL\"] and active_long_pos is None and active_short_pos is None:\n",
    "            cost = row.Close * n_shares * (1 + com)\n",
    "            if capital > cost:\n",
    "                capital -= cost\n",
    "                active_long_pos = {\n",
    "                    \"datetime\": row.Datetime,\n",
    "                    \"cost\": cost,\n",
    "                    \"take_profit\": row.Close * (1 + take_profit),\n",
    "                    \"stop_loss\": row.Close * (1 - stop_loss)\n",
    "                }\n",
    "\n",
    "        if row[\"SELL_SIGNAL\"] and active_short_pos is None and active_long_pos is None:\n",
    "            revenue = row.Close * n_shares * (1 - com)\n",
    "            capital += revenue\n",
    "            active_short_pos = {\n",
    "                \"datetime\": row.Datetime,\n",
    "                \"revenue\": revenue,\n",
    "                \"take_profit\": row.Close * (1 - take_profit),\n",
    "                \"stop_loss\": row.Close * (1 + stop_loss)\n",
    "            }\n",
    "\n",
    "        long_value = row.Close * n_shares if active_long_pos else 0\n",
    "        short_value = (active_short_pos[\"revenue\"] - row.Close * n_shares) if active_short_pos else 0\n",
    "        portfolio_value.append(capital + long_value + short_value)\n",
    "\n",
    "    if len(portfolio_value) <= 1:\n",
    "        return -float('inf')\n",
    "    metrics = calculate_metrics(portfolio_value, wins, losses)\n",
    "    return metrics[\"Sharpe\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dc36bef1-3073-4978-b49c-f405ab96ec31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 19:27:06,495] A new study created in memory with name: no-name-e1ab3475-4d02-439b-be73-5aa1fea73e05\n",
      "[W 2025-03-27 19:27:09,389] Trial 0 failed with parameters: {'bb_window': 14, 'bb_window_dev': 2.38699335707287, 'stop_loss': 0.18297057346367818, 'take_profit': 0.02095814166217433, 'n_shares': 3000, 'lookback': 33} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/46/p3w40sm501lfx91hwfw5sfmh0000gp/T/ipykernel_63405/1195347147.py\", line 3, in <lambda>\n",
      "    study_bb.optimize(lambda trial: objective_bb(trial, data), n_trials=50)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/46/p3w40sm501lfx91hwfw5sfmh0000gp/T/ipykernel_63405/1799593870.py\", line 20, in objective_bb\n",
      "    model = train_lstm(X_train, y_train, lookback=lookback)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/46/p3w40sm501lfx91hwfw5sfmh0000gp/T/ipykernel_63405/3297704670.py\", line 27, in train_lstm\n",
      "    model.fit(X_train, y_train, epochs=3, batch_size=32, verbose=0)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n",
      "    logs = self.train_function(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n",
      "    opt_outputs = multi_step_on_iterator(iterator)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n",
      "    results = tracing_compilation.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
      "    return function._call_flat(  # pylint: disable=protected-access\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1322, in _call_flat\n",
      "    return self._inference_function.call_preflattened(args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
      "    flat_outputs = self.call_flat(*args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
      "    outputs = self._bound_context.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/context.py\", line 1683, in call_function\n",
      "    outputs = execute.execute(\n",
      "              ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-03-27 19:27:09,390] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run the optimization\u001b[39;00m\n\u001b[1;32m      2\u001b[0m study_bb \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m study_bb\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective_bb(trial, data), n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejores parámetros BB:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study_bb\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     _optimize(\n\u001b[1;32m    476\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    477\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    478\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[1;32m    479\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    480\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    481\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[1;32m    482\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    483\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[1;32m    484\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[1;32m    485\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[1;32m     64\u001b[0m             study,\n\u001b[1;32m     65\u001b[0m             func,\n\u001b[1;32m     66\u001b[0m             n_trials,\n\u001b[1;32m     67\u001b[0m             timeout,\n\u001b[1;32m     68\u001b[0m             catch,\n\u001b[1;32m     69\u001b[0m             callbacks,\n\u001b[1;32m     70\u001b[0m             gc_after_trial,\n\u001b[1;32m     71\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     73\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[63], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run the optimization\u001b[39;00m\n\u001b[1;32m      2\u001b[0m study_bb \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m study_bb\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective_bb(trial, data), n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejores parámetros BB:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study_bb\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "Cell \u001b[0;32mIn[61], line 20\u001b[0m, in \u001b[0;36mobjective_bb\u001b[0;34m(trial, data, verbose)\u001b[0m\n\u001b[1;32m     17\u001b[0m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBB_upper\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m bb\u001b[38;5;241m.\u001b[39mbollinger_hband()\n\u001b[1;32m     19\u001b[0m X_train, y_train, X_test, y_test, scaler \u001b[38;5;241m=\u001b[39m prepare_lstm_data(dataset\u001b[38;5;241m.\u001b[39mdropna(), lookback\u001b[38;5;241m=\u001b[39mlookback, features\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBB\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 20\u001b[0m model \u001b[38;5;241m=\u001b[39m train_lstm(X_train, y_train, lookback\u001b[38;5;241m=\u001b[39mlookback)\n\u001b[1;32m     22\u001b[0m scaled_data \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(dataset[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBB\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m     23\u001b[0m X_full \u001b[38;5;241m=\u001b[39m [scaled_data[i \u001b[38;5;241m-\u001b[39m lookback:i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(lookback, \u001b[38;5;28mlen\u001b[39m(scaled_data))]\n",
      "Cell \u001b[0;32mIn[59], line 27\u001b[0m, in \u001b[0;36mtrain_lstm\u001b[0;34m(X_train, y_train, lookback, units)\u001b[0m\n\u001b[1;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 27\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1684\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1685\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1686\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1687\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1688\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1689\u001b[0m   )\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the optimization\n",
    "study_bb = optuna.create_study(direction=\"maximize\")\n",
    "study_bb.optimize(lambda trial: objective_bb(trial, data), n_trials=50)\n",
    "print(\"Mejores parámetros BB:\", study_bb.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ec35910-5a38-4fa5-966b-170d009fcdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare_lstm_data is defined as before\n",
    "def prepare_lstm_data(dataset, lookback=20, features=None):\n",
    "    if features is None:\n",
    "        features = [\"Close\", \"RSI\", \"BB\", \"MACD\", \"MACD_signal\"]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(dataset[features])\n",
    "    X, y = [], []\n",
    "    for i in range(lookback, len(scaled_data)):\n",
    "        X.append(scaled_data[i - lookback:i])\n",
    "        y.append(1 if scaled_data[i, 0] > scaled_data[i - 1, 0] else 0)  # Binary classification based on Close\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    train_size = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, scaler\n",
    "\n",
    "# Updated train_lstm with Input layer\n",
    "def train_lstm(X_train, y_train, lookback, units=50):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(units, return_sequences=False))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=3, batch_size=32, verbose=0)\n",
    "    return model\n",
    "\n",
    "# Updated calculate_metrics to handle NaN\n",
    "def calculate_metrics(portfolio_value, wins, losses):\n",
    "    returns = pd.Series(portfolio_value).pct_change().dropna()\n",
    "    mean_ret = returns.mean()\n",
    "    std_ret = returns.std()\n",
    "    if std_ret == 0 or np.isnan(mean_ret) or np.isnan(std_ret):\n",
    "        return {\"Sharpe\": -float('inf')}  # Penalize invalid cases\n",
    "    sharpe = (mean_ret / std_ret) * np.sqrt(252)  # Annualized Sharpe Ratio\n",
    "    return {\"Sharpe\": sharpe}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "008b5220-50c9-4212-b727-b2c08f53d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization for MACD\n",
    "\n",
    "# Objective function for MACD\n",
    "def objective_macd(trial, data, verbose=False):\n",
    "    # Hiperparámetros específicos de MACD\n",
    "    macd_window_slow = trial.suggest_int(\"macd_window_slow\", 20, 40)\n",
    "    macd_window_fast = trial.suggest_int(\"macd_window_fast\", 5, 20)\n",
    "    macd_window_sign = trial.suggest_int(\"macd_window_sign\", 5, 15)\n",
    "    \n",
    "    # Hiperparámetros generales de trading\n",
    "    stop_loss = trial.suggest_float(\"stop_loss\", 0.01, 0.2)\n",
    "    take_profit = trial.suggest_float(\"take_profit\", 0.01, 0.2)\n",
    "    n_shares = trial.suggest_categorical(\"n_shares\", [1000, 2000, 3000, 3500, 4000])\n",
    "    lookback = trial.suggest_int(\"lookback\", 10, 50)\n",
    "\n",
    "    dataset = data.copy()\n",
    "    macd = ta.trend.MACD(dataset.Close, window_slow=macd_window_slow, window_fast=macd_window_fast, window_sign=macd_window_sign)\n",
    "    dataset[\"MACD\"] = macd.macd()\n",
    "    dataset[\"MACD_signal\"] = macd.macd_signal()\n",
    "\n",
    "    X_train, y_train, X_test, y_test, scaler = prepare_lstm_data(dataset.dropna(), lookback=lookback, features=[\"Close\", \"MACD\", \"MACD_signal\"])\n",
    "    model = train_lstm(X_train, y_train, lookback=lookback)\n",
    "\n",
    "    scaled_data = scaler.transform(dataset[[\"Close\", \"MACD\", \"MACD_signal\"]])\n",
    "    X_full = [scaled_data[i - lookback:i] for i in range(lookback, len(scaled_data))]\n",
    "    X_full = np.array(X_full)\n",
    "    lstm_preds = (model.predict(X_full, verbose=0) > 0.5).astype(int).flatten()\n",
    "\n",
    "    dataset = dataset.iloc[lookback:].reset_index(drop=True)\n",
    "    dataset[\"LSTM_BUY\"] = pd.Series(lstm_preds) == 1\n",
    "    dataset[\"LSTM_SELL\"] = pd.Series(lstm_preds) == 0\n",
    "\n",
    "    dataset[\"MACD_BUY\"] = dataset[\"MACD\"] > dataset[\"MACD_signal\"]\n",
    "    dataset[\"MACD_SELL\"] = dataset[\"MACD\"] < dataset[\"MACD_signal\"]\n",
    "\n",
    "    dataset[\"BUY_SIGNAL\"] = dataset[\"MACD_BUY\"]\n",
    "    dataset[\"SELL_SIGNAL\"] = dataset[\"MACD_SELL\"]\n",
    "\n",
    "    dataset = dataset.dropna()\n",
    "    capital = 1000000\n",
    "    com = 0.5 / 100\n",
    "    portfolio_value = [capital]\n",
    "    active_long_pos = None\n",
    "    active_short_pos = None\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "\n",
    "    for i, row in dataset.iterrows():\n",
    "        if active_long_pos:\n",
    "            if row.Close < active_long_pos[\"stop_loss\"]:\n",
    "                pnl = row.Close * n_shares * (1 - com) - active_long_pos[\"cost\"]\n",
    "                capital += active_long_pos[\"cost\"] + pnl\n",
    "                if pnl > 0:\n",
    "                    wins += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "                active_long_pos = None\n",
    "            elif row.Close > active_long_pos[\"take_profit\"]:\n",
    "                pnl = row.Close * n_shares * (1 - com) - active_long_pos[\"cost\"]\n",
    "                capital += active_long_pos[\"cost\"] + pnl\n",
    "                if pnl > 0:\n",
    "                    wins += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "                active_long_pos = None\n",
    "\n",
    "        if active_short_pos:\n",
    "            if row.Close > active_short_pos[\"stop_loss\"]:\n",
    "                pnl = active_short_pos[\"revenue\"] - row.Close * n_shares * (1 + com)\n",
    "                capital += pnl\n",
    "                if pnl > 0:\n",
    "                    wins += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "                active_short_pos = None\n",
    "            elif row.Close < active_short_pos[\"take_profit\"]:\n",
    "                pnl = active_short_pos[\"revenue\"] - row.Close * n_shares * (1 + com)\n",
    "                capital += pnl\n",
    "                if pnl > 0:\n",
    "                    wins += 1\n",
    "                else:\n",
    "                    losses += 1\n",
    "                active_short_pos = None\n",
    "\n",
    "        if row[\"BUY_SIGNAL\"] and active_long_pos is None and active_short_pos is None:\n",
    "            cost = row.Close * n_shares * (1 + com)\n",
    "            if capital > cost:\n",
    "                capital -= cost\n",
    "                active_long_pos = {\n",
    "                    \"datetime\": row.Datetime,\n",
    "                    \"cost\": cost,\n",
    "                    \"take_profit\": row.Close * (1 + take_profit),\n",
    "                    \"stop_loss\": row.Close * (1 - stop_loss)\n",
    "                }\n",
    "\n",
    "        if row[\"SELL_SIGNAL\"] and active_short_pos is None and active_long_pos is None:\n",
    "            revenue = row.Close * n_shares * (1 - com)\n",
    "            capital += revenue\n",
    "            active_short_pos = {\n",
    "                \"datetime\": row.Datetime,\n",
    "                \"revenue\": revenue,\n",
    "                \"take_profit\": row.Close * (1 - take_profit),\n",
    "                \"stop_loss\": row.Close * (1 + stop_loss)\n",
    "            }\n",
    "\n",
    "        long_value = row.Close * n_shares if active_long_pos else 0\n",
    "        short_value = (active_short_pos[\"revenue\"] - row.Close * n_shares) if active_short_pos else 0\n",
    "        portfolio_value.append(capital + long_value + short_value)\n",
    "\n",
    "    if len(portfolio_value) <= 1:\n",
    "        return -float('inf')\n",
    "    metrics = calculate_metrics(portfolio_value, wins, losses)\n",
    "    return metrics[\"Sharpe\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ece86453-4ab9-41d8-a9ce-8ac96b2c4b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-27 19:28:26,392] A new study created in memory with name: no-name-9cdc9168-c418-4100-9a16-682fc3dbfa5d\n",
      "[W 2025-03-27 19:28:34,875] Trial 0 failed with parameters: {'macd_window_slow': 26, 'macd_window_fast': 5, 'macd_window_sign': 6, 'stop_loss': 0.1316624422138451, 'take_profit': 0.06642994117520674, 'n_shares': 3500, 'lookback': 35} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/46/p3w40sm501lfx91hwfw5sfmh0000gp/T/ipykernel_63405/431582906.py\", line 3, in <lambda>\n",
      "    study_macd.optimize(lambda trial: objective_macd(trial, data), n_trials=50)\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/46/p3w40sm501lfx91hwfw5sfmh0000gp/T/ipykernel_63405/1796038692.py\", line 22, in objective_macd\n",
      "    model = train_lstm(X_train, y_train, lookback=lookback)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/46/p3w40sm501lfx91hwfw5sfmh0000gp/T/ipykernel_63405/1055460615.py\", line 26, in train_lstm\n",
      "    model.fit(X_train, y_train, epochs=3, batch_size=32, verbose=0)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n",
      "    logs = self.train_function(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n",
      "    opt_outputs = multi_step_on_iterator(iterator)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 833, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 878, in _call\n",
      "    results = tracing_compilation.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
      "    return function._call_flat(  # pylint: disable=protected-access\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1322, in _call_flat\n",
      "    return self._inference_function.call_preflattened(args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
      "    flat_outputs = self.call_flat(*args)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
      "    outputs = self._bound_context.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/context.py\", line 1683, in call_function\n",
      "    outputs = execute.execute(\n",
      "              ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-03-27 19:28:34,878] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run the optimization\u001b[39;00m\n\u001b[1;32m      2\u001b[0m study_macd \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m study_macd\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective_macd(trial, data), n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejores parámetros MACD:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study_macd\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     _optimize(\n\u001b[1;32m    476\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    477\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    478\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[1;32m    479\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    480\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    481\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[1;32m    482\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    483\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[1;32m    484\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[1;32m    485\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[1;32m     64\u001b[0m             study,\n\u001b[1;32m     65\u001b[0m             func,\n\u001b[1;32m     66\u001b[0m             n_trials,\n\u001b[1;32m     67\u001b[0m             timeout,\n\u001b[1;32m     68\u001b[0m             catch,\n\u001b[1;32m     69\u001b[0m             callbacks,\n\u001b[1;32m     70\u001b[0m             gc_after_trial,\n\u001b[1;32m     71\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     73\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[69], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run the optimization\u001b[39;00m\n\u001b[1;32m      2\u001b[0m study_macd \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m study_macd\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective_macd(trial, data), n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejores parámetros MACD:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study_macd\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "Cell \u001b[0;32mIn[67], line 22\u001b[0m, in \u001b[0;36mobjective_macd\u001b[0;34m(trial, data, verbose)\u001b[0m\n\u001b[1;32m     19\u001b[0m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMACD_signal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m macd\u001b[38;5;241m.\u001b[39mmacd_signal()\n\u001b[1;32m     21\u001b[0m X_train, y_train, X_test, y_test, scaler \u001b[38;5;241m=\u001b[39m prepare_lstm_data(dataset\u001b[38;5;241m.\u001b[39mdropna(), lookback\u001b[38;5;241m=\u001b[39mlookback, features\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMACD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMACD_signal\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 22\u001b[0m model \u001b[38;5;241m=\u001b[39m train_lstm(X_train, y_train, lookback\u001b[38;5;241m=\u001b[39mlookback)\n\u001b[1;32m     24\u001b[0m scaled_data \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(dataset[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMACD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMACD_signal\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m     25\u001b[0m X_full \u001b[38;5;241m=\u001b[39m [scaled_data[i \u001b[38;5;241m-\u001b[39m lookback:i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(lookback, \u001b[38;5;28mlen\u001b[39m(scaled_data))]\n",
      "Cell \u001b[0;32mIn[65], line 26\u001b[0m, in \u001b[0;36mtrain_lstm\u001b[0;34m(X_train, y_train, lookback, units)\u001b[0m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 26\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1684\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1685\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1686\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1687\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1688\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1689\u001b[0m   )\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the optimization\n",
    "study_macd = optuna.create_study(direction=\"maximize\")\n",
    "study_macd.optimize(lambda trial: objective_macd(trial, data), n_trials=50)\n",
    "print(\"Mejores parámetros MACD:\", study_macd.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a1102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data: pd.DataFrame, *rsi_window: int, ...) -> pd.DataFrame:\n",
    "    \"\"\"Addd TA columns \n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Original data from csv\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: New data frame with RSI, BB and MACD\n",
    "    \"\"\"\n",
    "    dataset = data.copy()\n",
    "    rsi = ta.momentum.RSIIndicator(dataset.Close, window=rsi_window)\n",
    "    ...\n",
    "    dataset['RSI'] = rsi.rsi()\n",
    "    dataset['BB_MAVG'] = bb.bollinger_mavg()\n",
    "    dataset['BB_LOWER'] = bb.bollinger_lband()\n",
    "    dataset['BB_UPPER'] = bb.bollinger_hband()\n",
    "    dataset['MACD'] = macd.macd()\n",
    "    dataset['MACD_SIGNAL'] = macd.macd_signal()\n",
    "\n",
    "\n",
    "    # Signals\n",
    "    dataset['RSI_BUY'] = dataset['RSI'] < 25\n",
    "    dataset['RSI_SELL'] = dataset['RSI'] > 75\n",
    "\n",
    "    dataset['BB_BUY'] = bb.bollinger_lband_indicator().astype(bool)\n",
    "    dataset['BB_SELL'] = bb.bollinger_hband_indicator().astype(bool)\n",
    "\n",
    "    dataset['MACD_BUY'] = dataset['MACD'] > dataset['MACD_SIGNAL']\n",
    "    dataset['MACD_SELL'] = dataset['MACD'] < dataset['MACD_SIGNAL']\n",
    "\n",
    "    dataset = dataset.dropna()\n",
    "    dataset.head()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69df30c8-1efa-444c-a925-82a29034a750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular métricas\n",
    "def calculate_metrics(portfolio_value, wins, losses):\n",
    "    portfolio_series = pd.Series(portfolio_value)\n",
    "    if len(portfolio_series) < 2:\n",
    "        print(\"Error: portfolio_value tiene menos de 2 elementos\")\n",
    "        return {\"Sharpe\": 0, \"Sortino\": 0, \"Calmar\": 0, \"Win_Loss_Percent\": 0}\n",
    "    \n",
    "    returns = portfolio_series.pct_change().dropna()\n",
    "    if len(returns) == 0:\n",
    "        print(\"Error: No hay retornos válidos\")\n",
    "        return {\"Sharpe\": 0, \"Sortino\": 0, \"Calmar\": 0, \"Win_Loss_Percent\": 0}\n",
    "    \n",
    "    risk_free_rate = 0.0\n",
    "    sharpe = (returns.mean() - risk_free_rate) / returns.std() * np.sqrt(252 * 12)\n",
    "    downside_returns = returns[returns < 0]\n",
    "    sortino = (returns.mean() - risk_free_rate) / downside_returns.std() * np.sqrt(252 * 12) if len(downside_returns) > 0 else 0\n",
    "    cumulative_returns = (portfolio_series / portfolio_series.iloc[0] - 1)\n",
    "    max_drawdown = abs(cumulative_returns.min()) if cumulative_returns.min() != 0 else 1e-10\n",
    "    annual_return = (portfolio_series.iloc[-1] / portfolio_series.iloc[0] - 1) * (252 * 12 / len(returns))\n",
    "    calmar = annual_return / max_drawdown\n",
    "    total_trades = wins + losses\n",
    "    win_loss = wins / total_trades * 100 if total_trades > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"Sharpe\": sharpe if not np.isnan(sharpe) else 0,\n",
    "        \"Sortino\": sortino if not np.isnan(sortino) else 0,\n",
    "        \"Calmar\": calmar if not np.isnan(calmar) else 0,\n",
    "        \"Win_Loss_Percent\": win_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e63c0d-ca60-4559-9291-479c89b17691",
   "metadata": {},
   "source": [
    "### 4. Función Objetivo para Optimización\n",
    "\n",
    "Esta función se utiliza para evaluar la estrategia de trading en cada prueba de Optuna. En resumen, realiza los siguientes pasos:\n",
    "\n",
    "Generación de Hiperparámetros:\n",
    "* Se definen rangos para parámetros críticos (ventana y umbrales del RSI, stop loss, take profit, número de acciones y lookback) utilizando las sugerencias de Optuna.\n",
    "\n",
    "Cálculo de Indicadores Técnicos:\n",
    "* Se calculan los indicadores RSI, Bollinger Bands y MACD, y se añaden al dataset.\n",
    "\n",
    "Preparación y Entrenamiento del Modelo LSTM:\n",
    "* Se preparan los datos para el modelo (normalización y creación de secuencias temporales) y se entrena un modelo LSTM que se utiliza para predecir la dirección del movimiento del precio (compra/venta).\n",
    "\n",
    "Generación de Señales de Trading:\n",
    "* Se combinan las señales del modelo LSTM con las generadas por los indicadores técnicos para definir las órdenes de compra y venta.\n",
    "\n",
    "Simulación de Trading (Backtesting):\n",
    "* Se ejecuta un backtesting que simula operaciones (tanto long como short), actualizando el capital, el valor del portafolio y registrando las operaciones ganadoras y perdedoras.\n",
    "\n",
    "Cálculo del Desempeño:\n",
    "* Se calculan métricas clave (como el Sharpe Ratio, entre otras) a partir de la evolución del portafolio. El Sharpe ratio se devuelve como valor objetivo para la optimización.\n",
    "\n",
    "Esta función permite iterar sobre distintas combinaciones de hiperparámetros para encontrar la configuración que maximice el rendimiento ajustado por riesgo de la estrategia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a94b13c-7dc1-4dd6-a9a0-1757976885af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "# Crear y ejecutar el estudio\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(lambda trial: objective_fun(trial, data, verbose=False), n_trials=50)\n",
    "\n",
    "# Mostrar los mejores parámetros y el mejor valor\n",
    "print(f\"Mejor valor (Sharpe Ratio): {study.best_value}\")\n",
    "print(f\"Mejores parámetros: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad830d-bfa0-4ab0-80ec-86c73998557a",
   "metadata": {},
   "source": [
    "### 5. Optimización de Hiperparámetros con Optuna\n",
    "\n",
    "Esta parte del código se encarga de optimizar los hiperparámetros de la estrategia de trading utilizando Optuna. Primero, se crea un estudio cuyo objetivo es maximizar la función de rendimiento (en este caso, el Sharpe ratio). Luego, se ejecuta la optimización realizando 50 pruebas (trials), en cada una de las cuales se evalúa la función objetivo 'objective_fun' con distintas combinaciones de hiperparámetros. Esto permite identificar la configuración que proporciona el mejor rendimiento ajustado por riesgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e988a6f-4a9e-439b-821f-dc413ff8fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimización\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(lambda trial: objective_fun(trial, data), n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb05a9c-692f-4436-9370-9f1bfa184d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1066cd3c-d95f-433e-aef8-23752ade139c",
   "metadata": {},
   "source": [
    "### 6. Backtesting Final con Mejores Parámetros\n",
    "\n",
    "En esta sección se utiliza la mejor configuración de hiperparámetros obtenida en la optimización para ejecutar un backtesting completo de la estrategia. Se calculan nuevamente los indicadores técnicos (RSI, MACD y Bollinger Bands) aplicando los parámetros óptimos, se preparan los datos y se entrena el modelo LSTM. A partir de las predicciones del modelo y las señales generadas por los indicadores, se simula la ejecución de operaciones (compras y ventas cortas), actualizando el capital y registrando las operaciones ganadoras y perdedoras. Finalmente, se calcula el valor final del portafolio y se obtienen las métricas de desempeño para evaluar la eficacia de la estrategia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c2b1e-226a-4ec8-8abf-ef24690cb3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtesting final con mejores parámetros\n",
    "best_params = study.best_params\n",
    "rsi = ta.momentum.RSIIndicator(data.Close, window=best_params[\"rsi_window\"])\n",
    "macd = ta.trend.MACD(data.Close, window_slow=26, window_fast=12, window_sign=9)\n",
    "bb = ta.volatility.BollingerBands(data.Close, window=15, window_dev=2)  # Calculamos BB aquí\n",
    "\n",
    "dataset = data.copy()\n",
    "dataset[\"RSI\"] = rsi.rsi()\n",
    "dataset[\"MACD\"] = macd.macd()\n",
    "dataset[\"MACD_signal\"] = macd.macd_signal()\n",
    "dataset[\"BB\"] = bb.bollinger_mavg()  # Añadimos la media móvil de BB al dataset\n",
    "\n",
    "X_train, y_train, X_test, y_test, scaler = prepare_lstm_data(dataset.dropna(), lookback=best_params[\"lookback\"])\n",
    "model = train_lstm(X_train, y_train, lookback=best_params[\"lookback\"])\n",
    "scaled_data = scaler.transform(dataset[[\"Close\", \"RSI\", \"BB\", \"MACD\", \"MACD_signal\"]])\n",
    "X_full = [scaled_data[i-best_params[\"lookback\"]:i] for i in range(best_params[\"lookback\"], len(scaled_data))]\n",
    "X_full = np.array(X_full)\n",
    "lstm_preds = (model.predict(X_full, verbose=0) > 0.5).astype(int).flatten()\n",
    "\n",
    "dataset = dataset.iloc[best_params[\"lookback\"]:].reset_index(drop=True)\n",
    "dataset[\"LSTM_BUY\"] = pd.Series(lstm_preds) == 1\n",
    "dataset[\"LSTM_SELL\"] = pd.Series(lstm_preds) == 0\n",
    "\n",
    "# Recalculamos BB para las señales después de cortar dataset\n",
    "bb = ta.volatility.BollingerBands(dataset.Close, window=15, window_dev=2)\n",
    "dataset[\"RSI_BUY\"] = dataset[\"RSI\"] < best_params[\"rsi_lower\"]\n",
    "dataset[\"RSI_SELL\"] = dataset[\"RSI\"] > best_params[\"rsi_upper\"]\n",
    "dataset[\"BB_BUY\"] = dataset.Close < bb.bollinger_lband()\n",
    "dataset[\"BB_SELL\"] = dataset.Close > bb.bollinger_hband()\n",
    "dataset[\"MACD_BUY\"] = dataset[\"MACD\"] > dataset[\"MACD_signal\"]\n",
    "dataset[\"MACD_SELL\"] = dataset[\"MACD\"] < dataset[\"MACD_signal\"]\n",
    "\n",
    "dataset[\"BUY_SIGNAL\"] = (dataset[\"LSTM_BUY\"] | dataset[\"RSI_BUY\"] | dataset[\"BB_BUY\"] | dataset[\"MACD_BUY\"])\n",
    "dataset[\"SELL_SIGNAL\"] = (dataset[\"LSTM_SELL\"] | dataset[\"RSI_SELL\"] | dataset[\"BB_SELL\"] | dataset[\"MACD_SELL\"])\n",
    "\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "capital = 1000000\n",
    "com = 0.125 / 100\n",
    "portfolio_value = [capital]\n",
    "active_long_pos = None\n",
    "active_short_pos = None\n",
    "wins = 0\n",
    "losses = 0\n",
    "\n",
    "for i, row in dataset.iterrows():\n",
    "    if active_long_pos:\n",
    "        if row.Close < active_long_pos[\"stop_loss\"]:\n",
    "            pnl = row.Close * best_params[\"n_shares\"] * (1 - com) - active_long_pos[\"cost\"]\n",
    "            capital += active_long_pos[\"cost\"] + pnl\n",
    "            if pnl > 0:\n",
    "                wins += 1\n",
    "            else:\n",
    "                losses += 1\n",
    "            active_long_pos = None\n",
    "        elif row.Close > active_long_pos[\"take_profit\"]:\n",
    "            pnl = row.Close * best_params[\"n_shares\"] * (1 - com) - active_long_pos[\"cost\"]\n",
    "            capital += active_long_pos[\"cost\"] + pnl\n",
    "            if pnl > 0:\n",
    "                wins += 1\n",
    "            else:\n",
    "                losses += 1\n",
    "            active_long_pos = None\n",
    "\n",
    "    if active_short_pos:\n",
    "        if row.Close > active_short_pos[\"stop_loss\"]:\n",
    "            pnl = active_short_pos[\"revenue\"] - row.Close * best_params[\"n_shares\"] * (1 + com)\n",
    "            capital += active_short_pos[\"revenue\"] + pnl\n",
    "            if pnl > 0:\n",
    "                wins += 1\n",
    "            else:\n",
    "                losses += 1\n",
    "            active_short_pos = None\n",
    "        elif row.Close < active_short_pos[\"take_profit\"]:\n",
    "            pnl = active_short_pos[\"revenue\"] - row.Close * best_params[\"n_shares\"] * (1 + com)\n",
    "            capital += active_short_pos[\"revenue\"] + pnl\n",
    "            if pnl > 0:\n",
    "                wins += 1\n",
    "            else:\n",
    "                losses += 1\n",
    "            active_short_pos = None\n",
    "\n",
    "    if row[\"BUY_SIGNAL\"] and active_long_pos is None and active_short_pos is None:\n",
    "        cost = row.Close * best_params[\"n_shares\"] * (1 + com)\n",
    "        if capital > cost:\n",
    "            capital -= cost\n",
    "            active_long_pos = {\n",
    "                \"datetime\": row.Datetime,\n",
    "                \"cost\": cost,\n",
    "                \"take_profit\": row.Close * (1 + best_params[\"take_profit\"]),\n",
    "                \"stop_loss\": row.Close * (1 - best_params[\"stop_loss\"])\n",
    "            }\n",
    "\n",
    "    if row[\"SELL_SIGNAL\"] and active_short_pos is None and active_long_pos is None:\n",
    "        revenue = row.Close * best_params[\"n_shares\"] * (1 - com)\n",
    "        capital += revenue\n",
    "        active_short_pos = {\n",
    "            \"datetime\": row.Datetime,\n",
    "            \"revenue\": revenue,\n",
    "            \"take_profit\": row.Close * (1 - best_params[\"take_profit\"]),\n",
    "            \"stop_loss\": row.Close * (1 + best_params[\"stop_loss\"])\n",
    "        }\n",
    "\n",
    "    long_value = row.Close * best_params[\"n_shares\"] if active_long_pos else 0\n",
    "    short_value = (active_short_pos[\"revenue\"] - row.Close * best_params[\"n_shares\"]) if active_short_pos else 0\n",
    "    portfolio_value.append(capital + long_value + short_value)\n",
    "\n",
    "# Calcular métricas finales\n",
    "final_metrics = calculate_metrics(portfolio_value, wins, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f41f93d-d89d-4bf8-a487-43de5510d13a",
   "metadata": {},
   "source": [
    "### 7. Visualización y Resultados Finales\n",
    "\n",
    "Esta sección del código muestra el desempeño final de la estrategia. Se imprime el valor final del portafolio, los mejores parámetros obtenidos y las métricas de rendimiento (Sharpe Ratio, Sortino Ratio, Calmar Ratio y Win/Loss Percentage). Además, se genera una gráfica que compara la evolución del portafolio con el precio de cierre de las acciones de Apple, facilitando la interpretación visual de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e3d5ef-54f2-47ed-940f-5d4f4ba33444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resultados\n",
    "print(\"Mejor valor del portafolio:\", portfolio_value[-1])\n",
    "print(\"Mejores parámetros:\", best_params)\n",
    "print(\"Métricas finales:\")\n",
    "print(f\"Sharpe Ratio: {final_metrics['Sharpe']:.2f}\")\n",
    "print(f\"Sortino Ratio: {final_metrics['Sortino']:.2f}\")\n",
    "print(f\"Calmar Ratio: {final_metrics['Calmar']:.2f}\")\n",
    "print(f\"Win/Loss Percentage: {final_metrics['Win_Loss_Percent']:.2f}%\")\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(portfolio_value, label=\"Portfolio Value\")\n",
    "plt.legend()\n",
    "plt.twinx().plot(data.Close, c=\"orange\", label=\"AAPL Close\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd535db-46e3-408d-baf0-8040d1510715",
   "metadata": {},
   "source": [
    "### Conclusiones \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
